{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>2015-07-01</th>\n",
       "      <th>2015-07-02</th>\n",
       "      <th>2015-07-03</th>\n",
       "      <th>2015-07-04</th>\n",
       "      <th>2015-07-05</th>\n",
       "      <th>2015-07-06</th>\n",
       "      <th>2015-07-07</th>\n",
       "      <th>2015-07-08</th>\n",
       "      <th>2015-07-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-09-01</th>\n",
       "      <th>2017-09-02</th>\n",
       "      <th>2017-09-03</th>\n",
       "      <th>2017-09-04</th>\n",
       "      <th>2017-09-05</th>\n",
       "      <th>2017-09-06</th>\n",
       "      <th>2017-09-07</th>\n",
       "      <th>2017-09-08</th>\n",
       "      <th>2017-09-09</th>\n",
       "      <th>2017-09-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2PM_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3C_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4minute_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 804 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Page  2015-07-01  2015-07-02  \\\n",
       "0            2NE1_zh.wikipedia.org_all-access_spider        18.0        11.0   \n",
       "1             2PM_zh.wikipedia.org_all-access_spider        11.0        14.0   \n",
       "2              3C_zh.wikipedia.org_all-access_spider         1.0         0.0   \n",
       "3         4minute_zh.wikipedia.org_all-access_spider        35.0        13.0   \n",
       "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...         NaN         NaN   \n",
       "\n",
       "   2015-07-03  2015-07-04  2015-07-05  2015-07-06  2015-07-07  2015-07-08  \\\n",
       "0         5.0        13.0        14.0         9.0         9.0        22.0   \n",
       "1        15.0        18.0        11.0        13.0        22.0        11.0   \n",
       "2         1.0         1.0         0.0         4.0         0.0         3.0   \n",
       "3        10.0        94.0         4.0        26.0        14.0         9.0   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   2015-07-09     ...      2017-09-01  2017-09-02  2017-09-03  2017-09-04  \\\n",
       "0        26.0     ...            19.0        33.0        33.0        18.0   \n",
       "1        10.0     ...            32.0        30.0        11.0        19.0   \n",
       "2         4.0     ...             6.0         6.0         7.0         2.0   \n",
       "3        11.0     ...             7.0        19.0        19.0         9.0   \n",
       "4         NaN     ...            16.0        16.0        19.0         9.0   \n",
       "\n",
       "   2017-09-05  2017-09-06  2017-09-07  2017-09-08  2017-09-09  2017-09-10  \n",
       "0        16.0        27.0        29.0        23.0        54.0        38.0  \n",
       "1        54.0        25.0        26.0        23.0        13.0        81.0  \n",
       "2         4.0         7.0         3.0         4.0         7.0         6.0  \n",
       "3         6.0        16.0        19.0        30.0        38.0         4.0  \n",
       "4        20.0        23.0        28.0        14.0         8.0         7.0  \n",
       "\n",
       "[5 rows x 804 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv(\"/Users/YingShen/Desktop/Data_Science/SpringBorad/all/train_2.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ranges from 2015-07-01 to 2017-09-10\n"
     ]
    }
   ],
   "source": [
    "data_start_date = train_df.columns[1]\n",
    "data_end_date = train_df.columns[-1]\n",
    "print('Data ranges from %s to %s' % (data_start_date, data_end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "pred_steps = 62\n",
    "pred_length=timedelta(pred_steps)\n",
    "\n",
    "first_day = pd.to_datetime(data_start_date) \n",
    "last_day = pd.to_datetime(data_end_date)\n",
    "\n",
    "val_pred_start = last_day - pred_length + timedelta(1)\n",
    "val_pred_end = last_day\n",
    "\n",
    "train_pred_start = val_pred_start - pred_length\n",
    "train_pred_end = val_pred_start - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_length = train_pred_start - first_day\n",
    "\n",
    "train_enc_start = first_day\n",
    "train_enc_end = train_enc_start + enc_length - timedelta(1)\n",
    "\n",
    "val_enc_start = train_enc_start + pred_length\n",
    "val_enc_end = val_enc_start + enc_length - timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train encoding: 2015-07-01 00:00:00 - 2017-05-09 00:00:00\n",
      "Train prediction: 2017-05-10 00:00:00 - 2017-07-10 00:00:00 \n",
      "\n",
      "Val encoding: 2015-09-01 00:00:00 - 2017-07-10 00:00:00\n",
      "Val prediction: 2017-07-11 00:00:00 - 2017-09-10 00:00:00\n",
      "\n",
      "Encoding interval: 679\n",
      "Prediction interval: 62\n"
     ]
    }
   ],
   "source": [
    "print('Train encoding:', train_enc_start, '-', train_enc_end)\n",
    "print('Train prediction:', train_pred_start, '-', train_pred_end, '\\n')\n",
    "print('Val encoding:', val_enc_start, '-', val_enc_end)\n",
    "print('Val prediction:', val_pred_start, '-', val_pred_end)\n",
    "\n",
    "print('\\nEncoding interval:', enc_length.days)\n",
    "print('Prediction interval:', pred_length.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the NaN values with 0 since the dataset does not distinguish between 0 and missing\n",
    "df=train_df.fillna(0)\n",
    "\n",
    "visits_array = df[train_df.columns[1:]].values # (145063, 803)\n",
    "\n",
    "index_series = pd.Series(index=pd.Index([pd.to_datetime(i) for i in df.columns[1:]]),\n",
    "                          data=[j for j in range(len(df.columns[1:]))]) # (803,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func 1\n",
    "def get_time_block_series(visits_array, index_series, start_date, end_date):\n",
    "    ''' Return 145063 * (#day intervals) '''\n",
    "    idxs = index_series[start_date:end_date]\n",
    "    return visits_array[:,idxs]\n",
    "\n",
    "# func 2\n",
    "def transform_series_encode(visits_array):\n",
    "    ''' Standardize blocks of TS and transfer to Keras format '''\n",
    "    visits_array = np.log1p(visits_array) # log transform for computation\n",
    "    series_mean = visits_array.mean(axis=1).reshape(-1,1) \n",
    "    visits_array = visits_array - visits_mean # standardize\n",
    "    series_array = visits_array.reshape((visits_array.shape[0],visits_array.shape[1], 1))\n",
    "    # (n_series, n_timesteps, n_features) \n",
    "    \n",
    "    return series_array, series_mean\n",
    "\n",
    "# func 3\n",
    "def transform_series_decode(series_array, encode_series_mean):\n",
    "    \n",
    "    series_array = np.log1p(series_array) \n",
    "    series_array = series_array - encode_series_mean\n",
    "    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))\n",
    "    # (n_series, n_timesteps, n_features) \n",
    "    \n",
    "    return series_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters\n",
    "__latent_dim:__ \n",
    "The number of hidden units is a direct representation of the learning capacity of a NN; it reflects the number of learned parameters. Too many hidden features may perfectly fit the training data and cause over-fitting.<br>\n",
    "\n",
    "__drop out:__\n",
    "Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model # Import Keras Model API\n",
    "                               # e.g., model = Model(input=[a, b], output=c)\n",
    "from keras.layers import Input # Input() is used to instantiate a Keras tensor.\n",
    "from keras.layers import LSTM \n",
    "from keras.layers import Dense # Implement Output operation from input()\n",
    "from keras.optimizers import Adam\n",
    " \n",
    "latent_dim = 50 \n",
    "dropout = .20 \n",
    "\n",
    "# Define an input series and encode it with an LSTM. \n",
    "# A. Settle Encoder_LSTM fundation\n",
    "encoder_inputs = Input(shape=(None, 1)) \n",
    "encoder_lstm = LSTM(latent_dim, dropout=dropout, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the final states. These represent the \"context\"\n",
    "# vector that we use as the basis for decoding.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "# This is where teacher forcing inputs are fed in.\n",
    "decoder_inputs = Input(shape=(None, 1)) \n",
    "\n",
    "# We set up our decoder using `encoder_states` as initial state.  \n",
    "# We return full output sequences and return internal states as well. \n",
    "# We don't use the return states in the training model, but we will use them in inference.\n",
    "# B. Settle Decoder_LSTM fundation\n",
    "decoder_lstm = LSTM(latent_dim, dropout=dropout, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# C. 1 continuous output at each timestep\n",
    "decoder_dense = Dense(1) \n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# D. Define the model (shape) that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from our previous model - mapping encoder sequence to state vectors\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# A modified version of the decoding stage that takes in predicted target inputs\n",
    "# and encoded state vectors, returning predicted target outputs and decoder state vectors.\n",
    "# We need to hang onto these state vectors to run the next step of the inference loop.\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, 1))\n",
    "    \n",
    "    # Populate the first target sequence with end of encoding series pageviews\n",
    "    target_seq[0, 0, 0] = input_seq[0, -1, 0]\n",
    "\n",
    "    # Sampling loop for a batch of sequences - we will fill decoded_seq with predictions\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "\n",
    "    decoded_seq = np.zeros((1,pred_steps,1))\n",
    "    \n",
    "    for i in range(pred_steps):\n",
    "        \n",
    "        output, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        decoded_seq[0,i,0] = output[0,0,0]\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, 1))\n",
    "        target_seq[0, 0, 0] = output[0,0,0]\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
